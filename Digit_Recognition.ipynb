{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Handwritten-Digit-Recognition-CNN-TF.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toluwee/Machine_Learning_Projects/blob/master/Digit_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0OooYHX0gof"
      },
      "source": [
        "# Handwritten Digit Recognition using TensorFlow with and without Convolutions\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "bAAv_HxDZ5Gd"
      },
      "source": [
        "### About dataset\n",
        "The MNIST database of handwritten digits, available from http://yann.lecun.com/exdb/mnist/index.html and included in Keras dataset. It is a subset of a larger set available from NIST. The set of images in the MNIST database is a combination of two of NIST's databases: Special Database 1 and Special Database 3. Special Database 1 and Special Database 3 consist of digits written by high school students and employees of the United States Census Bureau, respectively. The digits have been size-normalized and centered in a fixed-size image.\n",
        "\n",
        "\n",
        "MNIST dataset has the following features:\n",
        "*   Dataset has a training set of 60,000 examples, and a test set of 10,000 examples.\n",
        "*   The size of each image is 28x28 pixels.\n",
        "*   Each image has only 1 color channel, i.e., grayscale image.\n",
        "*   Each pixel has value in the range of [0,255] where 0 represents black, and 255 represents white.\n",
        "*   Each image is labeled from 0-9.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glyvyvrvVfdc"
      },
      "source": [
        "## Objective \n",
        "\n",
        "1. To correctly identify digits from a dataset of tens of thousands of handwritten images.\n",
        "2. To compare the results of the generated model with and without using CNN and CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trGmvMr_DXho"
      },
      "source": [
        "## Methodology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "_G_802TrZ5GX"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "WhZBpCNgZ5GZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "ro_Yx9azZ5Ge"
      },
      "source": [
        "### Import dataset\n",
        "Load MNIST data from tf.keras datasets API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPfdobEh6EMx"
      },
      "source": [
        " mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu9rFb5fOFCJ"
      },
      "source": [
        "Load the data into two sets of lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g24tksYJOFox"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "58zBP00vZ5Gy"
      },
      "source": [
        "### Exploratory Analysis\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXhT7_A6OSDi"
      },
      "source": [
        "Next we visualize the input digits by plotting images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "yfAT95-2Z5G0"
      },
      "source": [
        "np.set_printoptions(linewidth=200) #These options determine the way floating point numbers, arrays and other NumPy objects are displayed.\n",
        "plt.imshow(training_images[1]) #Display data as an image; i.e. on a 2D regular raster\n",
        "print(training_labels[1])\n",
        "print(training_images[1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBfwq_lWvI6d"
      },
      "source": [
        "This will plot the first 30 images of digits with the label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2ZpZ1UGOmeX"
      },
      "source": [
        "rows = 5 # defining no. of rows in figure\n",
        "cols = 6 # defining no. of colums in figure\n",
        "\n",
        "f = plt.figure(figsize=(2*cols,2*rows)) # defining a figure \n",
        "\n",
        "for i in range(rows*cols): \n",
        "    f.add_subplot(rows,cols,i+1) # adding sub plot to figure on each iteration\n",
        "    plt.imshow(training_images[i].reshape([28,28]),cmap=\"Blues\") \n",
        "    plt.axis(\"off\")\n",
        "    plt.title(str(training_labels[i]), y=-0.15,color=\"green\")\n",
        "plt.savefig(\"digits.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czyoTNbz_Exk"
      },
      "source": [
        "### Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHbrT3WiBuqw"
      },
      "source": [
        "First we reshape the images to 4D   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW80I10rCRSJ"
      },
      "source": [
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "w5DscYWX_Exk"
      },
      "source": [
        "Now, we normalize the values \n",
        "\n",
        "*Important to only normalize the training and testing images, not the labels!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhk5tV4f_Exl"
      },
      "source": [
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw1pICgc_Exo"
      },
      "source": [
        "We write a code to initiate callback immediately a level of accuracy is achieved"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwQpNqU4_Exp"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.99):\n",
        "      print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAuHUPN6BXsY"
      },
      "source": [
        "### Model design\n",
        "\n",
        "Next, we design the model using Deep Neural network but with Convolution layers utilizing .Conv2D and .MaxPooling added on top. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "l2E1Uow08yU7"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5nha35l8yU_"
      },
      "source": [
        "**Sequential** groups a linear stack of layers into a tf.keras.Model\n",
        "\n",
        "**Flatten**: takes a square (28x28) image and turns it into a 1 dimensional set.\n",
        "\n",
        "**Dense**: Adds a layer of neurons \n",
        "  The middle layer is set to 512, can be varied to optimize model)\n",
        "  The output layer is set to 10, the number of features\n",
        "\n",
        "Each layer of neurons need an **activation function** to tell them what to do.\n",
        "\n",
        "**Relu** effectively means \"If X>0 return X, else return 0\" - it only passes values 0 or greater to the next layer in the network.\n",
        "\n",
        "**Softmax** takes a set of values, and effectively picks the biggest one. For example, if the output of the last layer is [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it turns into [0,0,0,0,1,0,0,0,0]\n",
        "\n",
        "**Conv2D.** 2D convolution layer (e.g. spatial convolution over images). This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.\n",
        "\n",
        "**MaxPool2D.** layer is used to reduce the size of the image. Pool size (2,2) means reducing the image from (28,28) to (14,14). Reducing the features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfUrAj008yU_"
      },
      "source": [
        "We then build the model with .compile and train it with .fit using the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOwRF3_ULQDo"
      },
      "source": [
        "model.compile(optimizer= tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(training_images, training_labels, epochs=20, callbacks=[callbacks])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "126lsPHk8yVF"
      },
      "source": [
        "We can use test images to see the model's performance on unseen data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvJVJ8K48yVG"
      },
      "source": [
        "model.evaluate(test_images,test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "hHVd4hl28yVJ"
      },
      "source": [
        "### Prediction\n",
        "Now we make prediction on the testing dataset and store it into a variable called classifications\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "HhcuSiEP8yVK"
      },
      "source": [
        "classifications = model.predict(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "yieGUB8N8yVO"
      },
      "source": [
        "<b>Classifications</b> are printed out to compare the prediction to the actual values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "scrolled": true,
        "id": "0kydaB3I8yVO"
      },
      "source": [
        "print (classifications [0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qa5NiVg8yVT"
      },
      "source": [
        "The 10 numbers obtained show the probability that the image belongs to a particular class.\n",
        "\n",
        "For the test_image at position 0, the 7th value has the highest probability. so that class is obtained from the key as an ankle boot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_DrBT4g8yVT"
      },
      "source": [
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "xzL_mVL38yVX"
      },
      "source": [
        "### Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXS4t93q8yVX"
      },
      "source": [
        "We can simply view the accuracy of the model as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "BHfkFaJU8yVY"
      },
      "source": [
        "history.epoch, history.history['accuracy'][-1]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}